{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import textract\n",
    "from typing import Dict\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import dataclasses\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa289e2aa91432990508d843b60801b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=138.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: to get textract to work here, we had to modify textract/parsers/utils.py\n",
    "# decode function to return UTF8 whenever the chardet confidence was not high\n",
    "# enough, eg:\n",
    "#\n",
    "#   result = chardet.detect(text)\n",
    "#   encoding = result['encoding'] if result['confidence'] > 0.85 else 'utf-8'\n",
    "#   return text.decode(encoding, 'ignore')\n",
    "#\n",
    "# We'd otherwise just get a bunch of UnicodeDecodeErrors\n",
    "\n",
    "# Paper struct\n",
    "@dataclasses.dataclass\n",
    "class Paper:\n",
    "    title: str\n",
    "    contents: str\n",
    "    extension: str\n",
    "\n",
    "\n",
    "# Load CSV\n",
    "with open(\"../masterdatafinal.csv\") as file:\n",
    "    csv_contents = list(csv.reader(file))\n",
    "\n",
    "# Load up all papers\n",
    "paper_from_id: Dict[int, Paper] = {}\n",
    "\n",
    "paper_paths = glob.glob(\"papers/*\")\n",
    "for path in tqdm(paper_paths):\n",
    "    paper_id, extension = os.path.basename(path).split(\".\")\n",
    "    paper_id = int(paper_id)\n",
    "\n",
    "    contents = textract.process(path).decode(\"utf8\")\n",
    "\n",
    "    # Keep only the first 70% or 500000 characters\n",
    "    # This is kind of a hack: gets rid of citations, speeds up computation, saves memory, etc\n",
    "    max_length = 500000\n",
    "    desired_length = min(int(len(contents) * 0.7), max_length)\n",
    "\n",
    "    contents = contents[:desired_length].rpartition(\" \")[0]\n",
    "    paper_from_id[paper_id] = Paper(\n",
    "        title=csv_contents[paper_id][1], contents=contents, extension=extension\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP stuff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just define a helper for pulling out keywords.\n",
    "\n",
    "We'll just use TextRank, which is maybe not state of the art but will hopefully be sufficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download language model\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "# Keyword struct\n",
    "@dataclasses.dataclass\n",
    "class Keyword:\n",
    "    keyword: str\n",
    "    count: int\n",
    "    rank: float\n",
    "\n",
    "\n",
    "# NLP helper\n",
    "import spacy\n",
    "import pytextrank\n",
    "import en_core_web_lg\n",
    "\n",
    "nlp = en_core_web_lg.load()\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "# Parsing helper\n",
    "def get_keywords(text):\n",
    "    # Get keywords\n",
    "    output = []\n",
    "    doc = nlp(text)\n",
    "    max_rank = 0\n",
    "    for p in doc._.phrases:\n",
    "        output.append(Keyword(keyword=p.text, count=p.count, rank=p.rank))\n",
    "        max_rank = max(max_rank, p.rank)\n",
    "\n",
    "    # Normalize ranks\n",
    "    for keyword in output:\n",
    "        keyword.rank = keyword.rank / max_rank\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword extraction took: 138.6468641757965 seconds\n"
     ]
    }
   ],
   "source": [
    "# Parallelized keyword extraction\n",
    "\n",
    "\n",
    "def _():\n",
    "    import multiprocessing\n",
    "    import time\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "\n",
    "    start_time = time.time()\n",
    "    keywords_list = pool.map(\n",
    "        get_keywords, [paper.contents for paper in paper_from_id.values()],\n",
    "    )\n",
    "    print(\"Keyword extraction took:\", time.time() - start_time, \"seconds\")\n",
    "\n",
    "    return keywords_list\n",
    "\n",
    "\n",
    "keywords_from_id = dict(zip(paper_from_id.keys(), _()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b328e12cbb43818e3800f7db320ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=138.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['a control policy', 'a function', 'a given state', 'a large number', 'a number', 'a random action', 'a real robot', 'a reward function', 'a set', 'a small number', 'a stochastic policy', 'a variety', 'a way', 'a wide range', 'abbeel', 'abbeel et al', 'abstract', 'access', 'account', 'accuracy', 'accurate models', 'action', 'action execution', 'action selection', 'actions', 'active learning', 'actuators', 'adaptation', 'adaptive control', 'addition', 'additional information', 'advance', 'advantage', 'agent', 'agents', 'algorithm', 'algorithms', 'an optimal policy', 'analysis', 'animals', 'application', 'applications', 'apprenticeship learning', 'approach', 'approaches', 'approximate inference', 'approximate inference methods', 'approximation', 'areas', 'artificial agents', 'artificial intelligence', 'artificial neural networks', 'artificial systems', 'assumptions', 'atkeson', 'attention', 'autonomous mental development', 'autonomous robots', 'autonomous systems', 'background', 'bagnell', 'barto', 'basis functions', 'bayes', 'bayesian', 'bayesian models', 'behavior', 'behaviors', 'bellman', 'bertsekas', 'better performance', 'biological systems', 'blocks', 'boxes', 'brain', 'cambridge', 'cameras', 'carnegie mellon university', 'cartesian', 'cases', 'categories', 'center', 'challenges', 'change', 'changes', 'children', 'classification', 'closed form', 'cognitive robotics', 'cognitive science', 'cognitive sciences', 'collisions', 'color', 'commands', 'communication', 'comparison', 'complex models', 'complex policies', 'complex tasks', 'complexity', 'components', 'computation', 'computation time', 'computational models', 'computer science', 'computer science department', 'computer vision', 'computing', 'concepts', 'conditions', 'connections', 'constraints', 'contact', 'context', 'continuous actions', 'continuous control', 'continuous state and action spaces', 'continuous states', 'contrast', 'control', 'control algorithms', 'control policies', 'control problems', 'control systems', 'control theory', 'controller', 'controllers', 'convergence', 'convolutional neural networks', 'cookies', 'cost function', 'cost functions', 'costs', 'course', 'covariance', 'current state', 'data collection', 'data points', 'datasets', 'decisions', 'deep convolutional neural networks', 'deep learning', 'deep learning algorithms', 'deep networks', 'deep neural networks', 'deep reinforcement learning', 'deformable objects', 'deisenroth et al', 'demonstration', 'demonstrations', 'department', 'depth', 'design', 'detail', 'details', 'deterministic models', 'deterministic policies', 'development', 'developmental psychology', 'different actions', 'different approaches', 'different behaviors', 'different levels', 'different objects', 'different properties', 'different states', 'different tasks', 'different types', 'different values', 'different ways', 'dimensionality', 'direct learning', 'discrete actions', 'discrete states', 'discrete time', 'discrete variables', 'discussion', 'distribution', 'distributions', 'domain knowledge', 'domains', 'duan et al', 'dynamic programming', 'dynamic programming methods', 'dynamic systems', 'dynamic time warping', 'dynamical systems', 'dynamics', 'dynamics model', 'dynamics models', 'each time step', 'effect', 'effects', 'efficient learning', 'elements', 'empirical results', 'engineering', 'environment', 'environments', 'equation', 'equations', 'error', 'errors', 'estimation', 'et al', 'evaluation', 'evolution', 'evolutionary algorithms', 'example', 'examples', 'execution', 'existing algorithms', 'existing methods', 'expected reward', 'experience', 'experimental data', 'experimental results', 'experiments', 'expert demonstrations', 'exploration', 'factors', 'familiar objects', 'fast learning', 'features', 'feedback', 'field', 'figure', 'first', 'fitness', 'forces', 'freedom', 'friction', 'front', 'function', 'function approximation', 'function approximators', 'functions', 'future rewards', 'future work', 'games', 'gaussian', 'gaussian distributions', 'gaussian model', 'gaussian noise', 'gaussian processes', 'generalization', 'generative models', 'genetic algorithms', 'germany', 'goal states', 'goals', 'good models', 'good performance', 'good policies', 'good results', 'gradient', 'gradient descent', 'gradient methods', 'gradients', 'graphs', 'grasp planning', 'grasping points', 'grasps', 'gravity', 'gripper', 'guided policy search', 'height', 'helicopters', 'hidden markov models', 'hidden units', 'high speed', 'human demonstration', 'human motion', 'human performance', 'humanoid robots', 'humans', 'ideas', 'ieee international conference', 'ieee transactions', 'image classification', 'image patches', 'images', 'imitation', 'imitation learning', 'improvement', 'inaccurate models', 'incremental learning', 'index terms', 'individuals', 'inference', 'inference methods', 'information', 'initial state', 'initial states', 'input', 'input data', 'inputs', 'instance', 'intelligent robots', 'interaction', 'interactions', 'interest', 'internal models', 'introduction', 'inverse models', 'inverse reinforcement learning', 'iteration', 'iterations', 'iterative learning control', 'joint angles', 'joint positions', 'joint space', 'joint torques', 'joint velocities', 'joints', 'kalman', 'knowledge', 'known objects', 'kroemer et al', 'large amounts', 'large neural networks', 'large numbers', 'large objects', 'layer', 'layers', 'learn', 'learned models', 'learned policies', 'learning', 'learning algorithms', 'learning control', 'learning methods', 'learning systems', 'learning tasks', 'legged robots', 'length', 'length t', 'levine et al', 'lifelong learning', 'linear', 'linear equations', 'linear function approximation', 'linear models', 'linear regression', 'local models', 'local optima', 'locomotion', 'los angeles', 'machine learning', 'machine learning methods', 'machines', 'magnitude', 'main content', 'manipulation', 'manipulation tasks', 'many algorithms', 'many applications', 'many approaches', 'many cases', 'many objects', 'many problems', 'many tasks', 'mapping', 'markov', 'markov decision processes', 'matrices', 'means', 'measurements', 'memory', 'methods', 'mit press', 'miyamoto et al', 'mnih et al', 'mobile robots', 'model', 'model errors', 'model learning', 'model parameters', 'model predictive control', 'model uncertainty', 'models', 'monte carlo', 'moore', 'more data', 'more detail', 'more details', 'more information', 'most cases', 'motion', 'motion planning', 'motions', 'motor', 'motor commands', 'motor control', 'motor learning', 'motor primitives', 'motor skills', 'motors', 'movement', 'movement recognition', 'movements', 'multiple demonstrations', 'multiple objects', 'multiple tasks', 'natural policy gradients', 'nature', 'network', 'networks', 'neural', 'neural information processing systems', 'neural network', 'neural network models', 'neural network policies', 'neural networks', 'neurons', 'neuroscience', 'new algorithms', 'new data', 'new objects', 'new situations', 'new tasks', 'next state', 'next states', 'ng et al', 'nodes', 'noise', 'noisy observations', 'nonlinear systems', 'nonparametric models', 'notation', 'novel objects', 'number', 'object features', 'object localization', 'object properties', 'object recognition', 'object segmentation', 'object shape', 'objects', 'observation', 'observations', 'obstacle avoidance', 'obstacles', 'online learning', 'operational space control', 'optimal actions', 'optimal behavior', 'optimal control', 'optimal control problems', 'optimal policies', 'optimal policy', 'optimization', 'order', 'orientation', 'other agents', 'other approaches', 'other methods', 'other objects', 'other robots', 'other tasks', 'other words', 'others', 'our approach', 'output', 'outputs', 'parallel', 'parameter space', 'parameter values', 'parameters', 'parametric models', 'people', 'perception', 'performance', 'perturbations', 'peters', 'physical systems', 'physics', 'pieter abbeel', 'pixels', 'place', 'planning', 'point', 'points', 'policies', 'policy', 'policy evaluation', 'policy gradient', 'policy gradient estimation', 'policy gradient methods', 'policy gradient reinforcement learning', 'policy gradients', 'policy improvement', 'policy iteration', 'policy learning', 'policy optimization', 'policy parameters', 'policy search', 'policy search methods', 'policy space', 'policy training', 'position', 'positions', 'possible actions', 'possible states', 'practice', 'prediction', 'predictions', 'previous algorithms', 'previous approaches', 'previous policies', 'previous work', 'principle', 'prior knowledge', 'prior methods', 'prior work', 'probabilistic', 'probabilistic inference', 'probabilistic models', 'probability', 'probability distributions', 'problem', 'problems', 'proceedings', 'processes', 'progress', 'properties', 'psychology', 'q learning', 'q values', 'questions', 'random noise', 'random variables', 'raw images', 'real data', 'real images', 'real robots', 'real systems', 'real time', 'reality', 'recent work', 'recent years', 'recognition', 'recurrent neural networks', 'recurrent policies', 'references', 'regions', 'regression', 'reinforcement', 'reinforcement learning', 'reinforcement learning algorithms', 'reinforcement learning methods', 'reinforcement learning problems', 'related work', 'relation', 'representation', 'representations', 'research', 'researchers', 'respect', 'response', 'results', 'return', 'reward', 'reward function', 'reward functions', 'rewards', 'rhythmic movements', 'rl algorithms', 'rl methods', 'rl problems', 'robot', 'robot control', 'robot learning', 'robot motion', 'robot programming', 'robotic control', 'robotic grasping', 'robotic manipulation', 'robotic manipulation tasks', 'robotic systems', 'robotic tasks', 'robotics', 'robots', 'robustness', 'rotation', 'sample trajectories', 'samples', 'sampling', 'schaal', 'schulman et al', 'science', 'scratch', 'search', 'second', 'section', 'section iii', 'section iv', 'section v', 'sensor data', 'sensors', 'sensory data', 'sequence', 'sequences', 'sergey levine', 'several approaches', 'several examples', 'several ways', 'shape', 'signals', 'similar objects', 'simplicity', 'simulation', 'situations', 'skills', 'solutions', 'southern california', 'space', 'sparse rewards', 'specific objects', 'speed', 'stability', 'stable grasps', 'standard deviation', 'stanford', 'stanford university', 'state', 'state estimation', 'state s', 'state space', 'state transitions', 'state variables', 'states', 'states s', 'statistics', 'stefan schaal', 'steps', 'stochastic gradient descent', 'stochastic optimal control', 'stochastic policies', 'strategies', 'structure', 'studies', 'success', 'such actions', 'such approaches', 'such cases', 'such data', 'such information', 'such methods', 'such models', 'such problems', 'such systems', 'such tasks', 'summary', 'supervised learning', 'supervised learning methods', 'supervised learning problems', 'sutton', 'sutton et al', 'synthetic data', 'system', 'system dynamics', 'system identification', 'systems', 't steps', 'table', 'targets', 'task space', 'tasks', 'taylor', 'td learning', 'techniques', 'technology', 'terms', 'test data', 'test time', 'testing', 'the ability', 'the action space', 'the amount', 'the best action', 'the case', 'the center', 'the context', 'the control problem', 'the cost function', 'the covariance matrix', 'the current policy', 'the current state', 'the dynamics', 'the end', 'the environment', 'the expected value', 'the fact', 'the field', 'the final policy', 'the following sections', 'the form', 'the function', 'the goal', 'the goal state', 'the gradient', 'the ground', 'the idea', 'the initial state', 'the learned model', 'the learned policies', 'the learned policy', 'the learning agent', 'the learning algorithm', 'the learning problem', 'the learning process', 'the learning rate', 'the learning system', 'the model', 'the model parameters', 'the need', 'the network', 'the next section', 'the next state', 'the number', 'the optimal action', 'the optimal policy', 'the other hand', 'the parameters', 'the performance', 'the policy parameters', 'the position', 'the previous section', 'the probability', 'the problem', 'the process', 'the quality', 'the real world', 'the resulting policy', 'the same task', 'the same time', 'the same way', 'the search space', 'the set', 'the space', 'the state space', 'the system', 'the system dynamics', 'the total number', 'the training data', 'the training set', 'the use', 'the value', 'the value function', 'the world', 'theorem', 'theory', 'third', 'this approach', 'this paper', 'this problem', 'this section', 'this work', 'thousands', 'time step', 'time step t', 'time steps', 'time t', 'torques', 'training', 'training data', 'training examples', 'training iterations', 'training time', 'trajectories', 'trajectory', 'trajectory optimization', 'trajectory planning', 'transitions', 'trial', 'trials', 'trust region policy optimization', 'uncertainty', 'understanding', 'units', 'university', 'unknown objects', 'unsupervised learning', 'value', 'value function', 'value function approximation', 'value functions', 'value iteration', 'values', 'variables', 'variance', 'variations', 'various objects', 'vectors', 'velocities', 'velocity', 'vision', 'visual features', 'visual feedback', 'visual information', 'visual perception', 'volume', 'walking', 'walking robots', 'wang et al', 'weights', 'ziebart et al']\n"
     ]
    }
   ],
   "source": [
    "# Consolidate keywords: help us determine which ones to actually use\n",
    "def list_top_keywords():\n",
    "    all_keyword_map = {}\n",
    "    for keywords in tqdm(keywords_from_id.values()):\n",
    "        for keyword in keywords:\n",
    "            if keyword.keyword in all_keyword_map:\n",
    "                all_keyword_map[keyword.keyword].count += keyword.count\n",
    "                all_keyword_map[keyword.keyword].rank += keyword.rank\n",
    "            else:\n",
    "                all_keyword_map[keyword.keyword] = Keyword(\n",
    "                    **dataclasses.asdict(keyword)\n",
    "                )\n",
    "\n",
    "    # Print out top 1000 keywords in alphabetical order\n",
    "    sorted_keywords = sorted(\n",
    "        all_keyword_map.keys(), key=lambda k: -all_keyword_map[k].rank\n",
    "    )\n",
    "\n",
    "    def is_valid(k):\n",
    "        if len(k) <= 4:\n",
    "            return False\n",
    "        if len(set(k) - set(\"abcdefghijklmnopqrstuvwxyz \")) > 0:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    # Print out top ~1000 keywords, sorted alphabetically\n",
    "    print(sorted(filter(is_valid, sorted_keywords[:1000])))\n",
    "\n",
    "\n",
    "list_top_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del curated_keyword_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 120 total keywords, 25 unique\n"
     ]
    }
   ],
   "source": [
    "from curated_keywords import curated_keyword_map\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(curated_keyword_map)} total keywords, {len(set(curated_keyword_map.values()))} unique\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact dynamics (4) genetic algorithms (7) evolution (8) cognitive sciences (9) unsupervised learning (9) nonlinear systems (10) legged robots (10) dynamic programming (13) trajectory optimization (13) humanoid robotics (14) locomotion (15) survey (17) mobile robots (18) policy gradients (22) state estimation (23) gaussians (24) manipulation (25) visual perception (26) optimal control (27) planning (32) probabilistic models (34) dynamical systems (41) neural networks (44) learning from demonstration (48) reinforcement learning (77) \n"
     ]
    }
   ],
   "source": [
    "def _():\n",
    "    top_keywords_from_id = {}\n",
    "\n",
    "    rank_threshold = 0.6\n",
    "    count_threshold = 2\n",
    "    min_keywords = 4\n",
    "\n",
    "    import collections\n",
    "\n",
    "    keyword_counts = collections.defaultdict(lambda: 0)\n",
    "\n",
    "    for paper_id, keywords in keywords_from_id.items():\n",
    "        paper_keyword_counts = collections.defaultdict(lambda: 0)\n",
    "        for k in keywords:\n",
    "            if (\n",
    "                k.rank <= rank_threshold\n",
    "                and len(paper_keyword_counts) >= min_keywords\n",
    "            ):\n",
    "                break\n",
    "\n",
    "            if k.keyword not in curated_keyword_map:\n",
    "                continue\n",
    "\n",
    "            nominal = curated_keyword_map[k.keyword]\n",
    "            if nominal not in paper_keyword_counts:\n",
    "                keyword_counts[nominal] += 1\n",
    "            paper_keyword_counts[nominal] += k.count\n",
    "\n",
    "        top_keywords = (\n",
    "            []\n",
    "        )  # A set would work here, but ordering is not supported natively\n",
    "        for keyword, count in paper_keyword_counts.items():\n",
    "            if count >= count_threshold and keyword not in top_keywords:\n",
    "                top_keywords.append(keyword)\n",
    "\n",
    "        for keyword, nominal in curated_keyword_map.items():\n",
    "            if (\n",
    "                keyword in paper_from_id[paper_id].title.lower()\n",
    "                or (\n",
    "                    nominal not in (\"reinforcement learning\")\n",
    "                    and keyword in csv_contents[paper_id][5].lower()\n",
    "                )\n",
    "            ) and nominal not in top_keywords:\n",
    "                top_keywords.insert(0, nominal)\n",
    "                keyword_counts[nominal] += 1\n",
    "\n",
    "        if len(top_keywords) > 0:\n",
    "            top_keywords_from_id[paper_id] = top_keywords\n",
    "\n",
    "    for k in sorted(keyword_counts.keys(), key=lambda k: keyword_counts[k]):\n",
    "        print(f\"{k} ({keyword_counts[k]}) \", end=\"\")\n",
    "    print()\n",
    "    return top_keywords_from_id\n",
    "\n",
    "\n",
    "top_keywords_from_id = _()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20: a survey on policy search for robotics\n",
      "34: a survey of iterative learning control\n",
      "43: robots that can adapt like animals\n",
      "61: is imitation learning the route to humanoid robots?\n",
      "72: data-driven grasp synthesis-a survey\n",
      "76: reinforcement learning: a survey\n",
      "84: an algorithmic perspective on imitation learning\n",
      "93: model learning for robot control: a survey\n",
      "94: a brief survey of deep reinforcement learning\n",
      "96: locally weighted learning and locally weighted learning for control\n",
      "97: reinforcement learning in robotics: a survey\n",
      "101: cognitive developmental robotics: a survey\n",
      "129: affordances in psychology|neuroscience and robotics: a survey\n",
      "130: assessing grasp stability based on learning and haptic data\n",
      "144: learning control in robotics\n",
      "145: a review of robot learning for manipulation: challenges, representations, and algorithms\n",
      "['optimal control']\n"
     ]
    }
   ],
   "source": [
    "not_surveys = (130, 43)\n",
    "\n",
    "for paper_id in sorted(top_keywords_from_id.keys()):\n",
    "    keywords = top_keywords_from_id[paper_id]\n",
    "    if \"survey\" in keywords:\n",
    "        if paper_id in not_surveys:\n",
    "            keywords.remove(\"survey\")\n",
    "        print(f\"{paper_id}: {paper_from_id[paper_id].title}\")\n",
    "\n",
    "print(top_keywords_from_id[128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 applied nonlinear control\n",
      "50 robot skill learning: from reinforcement learning to evolution strategies\n",
      "70 robotics|vision and control - fundamental algorithms in matlab\n",
      "73 a simple learning strategy for high-speed quadrocopter multi-flips\n",
      "102 on the adaptive control of robot manipulator\n",
      "105 forward models: supervised learning with a distal teacher\n",
      "109 representations for robot knowledge in the knowrob framework\n",
      "115 resilient machines through continuous self-modeling\n",
      "120 how the body shapes the way we think: a new view of intelligence\n",
      "132 optimal control and estimation\n",
      "139 sequential composition of dynamically dexterous robot behaviors\n",
      "140 map learning with uninterpreted sensors and effectors\n",
      "141 experiments in synthetic psychology\n"
     ]
    }
   ],
   "source": [
    "# Print papers with missing keywords\n",
    "for id in sorted(\n",
    "    set(range(1, len(csv_contents))) - set(top_keywords_from_id.keys())\n",
    "):\n",
    "    print(id, csv_contents[id][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the coordination of arm movements: an experimentally confirmed mathematical model\n",
      "Current: ['optimal control']\n",
      "Adding: ['cognitive sciences', 'dynamical systems']\n",
      "closing the sim-to-real loop: adapting simulation randomization with real world experience\n",
      "Current: ['reinforcement learning']\n",
      "Adding: ['policy gradients', 'manipulation']\n"
     ]
    }
   ],
   "source": [
    "manual_keywords_from_id = {\n",
    "    31: [\"nonlinear systems\", \"optimal control\"],  # applied nonlinear control\n",
    "    50: [\n",
    "        \"reinforcement learning\",\n",
    "        \"evolution\",\n",
    "    ],  # robot skill learning: from reinforcement learning to evolution strategies\n",
    "    70: [\n",
    "        \"visual perception\"\n",
    "    ],  # robotics|vision and control - fundamental algorithms in matlab\n",
    "    73: [\n",
    "        \"policy gradients\"\n",
    "    ],  # a simple learning strategy for high-speed quadrocopter multi-flips\n",
    "    102: [\n",
    "        \"dynamical systems\",\n",
    "        \"manipulation\",\n",
    "    ],  # on the adaptive control of robot manipulator\n",
    "    105: [\n",
    "        \"dynamical systems\",\n",
    "        \"neural networks\",\n",
    "    ],  # forward models: supervised learning with a distal teacher\n",
    "    109: [],  # representations for robot knowledge in the knowrob framework\n",
    "    115: [\n",
    "        \"legged robots\",\n",
    "        \"locomotion\",\n",
    "    ],  # resilient machines through continuous self-modeling\n",
    "    120: [\n",
    "        \"cognitive sciences\"\n",
    "    ],  # how the body shapes the way we think: a new view of intelligence\n",
    "    128: [\n",
    "        \"cognitive sciences\",\n",
    "        \"dynamical systems\",\n",
    "    ],  # the coordination of arm movements: an experimentally confirmed mathematical model\n",
    "    132: [\n",
    "        \"optimal control\",\n",
    "        \"state estimation\",\n",
    "    ],  # optimal control and estimation\n",
    "    139: [\n",
    "        \"dynamical systems\",\n",
    "    ],  # sequential composition of dynamically dexterous robot behaviors\n",
    "    140: [],  # map learning with uninterpreted sensors and effectors\n",
    "    141: [\"cognitive sciences\"],  # experiments in synthetic psychology\n",
    "    146: [\"policy gradients\", \"manipulation\"]  # closing the sim-to-real loop: adapting simulation randomization with real world experience\n",
    "}\n",
    "\n",
    "# Validate\n",
    "for k, v in manual_keywords_from_id.items():\n",
    "    if k in top_keywords_from_id:\n",
    "        print(paper_from_id[k].title)\n",
    "        print(\"Current:\", top_keywords_from_id[k])\n",
    "        print(\"Adding:\", v)\n",
    "        top_keywords_from_id[k].extend(\n",
    "            [\n",
    "                keyword\n",
    "                for keyword in v\n",
    "                if keyword not in top_keywords_from_id[k]\n",
    "            ]\n",
    "        )\n",
    "    for keyword in v:\n",
    "        assert curated_keyword_map[keyword] == keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep copy CSV contents\n",
    "new_csv_contents = [row[:] for row in csv_contents]\n",
    "new_csv_contents[0].append(\"Keywords\")\n",
    "\n",
    "for row in new_csv_contents[1:]:\n",
    "    paper_id = int(row[0])\n",
    "    if paper_id in top_keywords_from_id:\n",
    "        keywords = top_keywords_from_id[paper_id]\n",
    "    else:\n",
    "        keywords = manual_keywords_from_id[paper_id]\n",
    "    row.append(\",\".join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./masterdata_keywords.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    for row in new_csv_contents:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords_from_id[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
